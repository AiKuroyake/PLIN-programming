{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12fb326a",
   "metadata": {},
   "source": [
    "# Tokenizace\n",
    "\n",
    "V tomto notebooku si v několika krocích vytvoříme program pro tokenizaci textu. Použijeme k tomu pouze základní metody Pythonu a knihovnu re pro regulární výrazy.\n",
    "\n",
    "Tokenizace je jedním z běžných problémů zpracování přirozeného jazyka. S tokenizací se setkáme v korpusech, v syntéze řeči, během strojového učení apod. Jedná se o rozdělení textu na menší části, přičemž tyto části, kterým říkáme tokeny, mohou být věty, slova, či jinak definované řetězce. Jelikož se jedná o běžnou součást NLP (zpracování přirozeného jazyka; z anglického Natural Language Processing), mohli bychom předpokládat, že tokenizace patří mezi dobře popsané problémy, který není třeba řešit. Jak si ale ukážeme dále, s tokenizací to není tak jednoduché a velmi záleží na tom, pro co data zpracováváme a jak definujeme samotné tokeny.\n",
    "\n",
    "## 1 Problémy tokenizace\n",
    "\n",
    "Pokud se zaměříme na tokenizaci slov, musíme se rozhodnout, jak budeme ke slovům přistupovat. Pokud narazíme na slovní spojení \"Jižní Amerika\", budeme jej tokenizovat jako dvě různá slova \"Jižní\" a \"Amerika\", nebo zvolíme variantu \"Jižní Amerika\", jelikož tato dvě slova tvoří pojmenovanou entitu? Jak v anglickém textu budeme tokenizovat \"don't\"? Přikloníme se k variantě \"don't\", \"do\" a \"n't\", \"dont\", nebo úplně jiné variantě? Pokud narazíme na slovo \"překladatel-tlumočník\", rozhodneme se ho ponechat se spojovníkem nebo rozdělit do slov \"překladatel\" a \"tlumočník\"?  A co slovo \"dvou-\" ve spojení \"dvou‑ až třílůžkový pokoj\"? Jak budeme nakládat s daty, čísly, zkratkami, internetovými adresami, interpunkcí apod.?\n",
    "\n",
    "Seznam by mohl dále pokračovat. Z předchozích příkladů můžeme vidět, že problémů definice slova (tokenu) je spousta, přičemž žádný z uvedených příkladů nemá jedno správné řešení, všechna uvedená by byla vhodná v různých kontextech.\n",
    "\n",
    "V našem případě nebude důležité vyřešit všechny tyto problémy. Zaměříme se pouze na ty, které se vyskytují v textu, jenž budeme tokenizovat.\n",
    "\n",
    "## 2 S čím budeme pracovat\n",
    "\n",
    "### 2.1 re\n",
    "\n",
    "V tomto notebooku použijeme modul re, který slouží pro práci s regulárními výrazy.\n",
    "\n",
    "Více informací na [re](https://docs.python.org/3/library/re.html) nebo [Programiz](https://www.programiz.com/python-programming/regex).\n",
    "\n",
    "Pro připomenutí regulárních výrazů vám může pomoct tento [cheatsheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/). Než výrazy implementujete do svého kódu, můžete si jejich funkčnost vyzkoušet např. na [regex101](https://regex101.com/) (nezapomeňte si v levém boxu přepnout flavor na Python).\n",
    "\n",
    "## 3 Instalace\n",
    "\n",
    "Modul re je součástí tzv. The Python Standard Library (standarní knihovny Pythonu), není tedy nutné nic instalovat.\n",
    "\n",
    "Více informací na [The Python Standard Library](https://docs.python.org/3/library/).\n",
    "\n",
    "## 4 Import knihoven a modulů\n",
    "\n",
    "Než budeme moct začít s psaním programu, musíme importovat všechny knihovny a moduly, které budeme potřebovat. Patří mezi ně:\n",
    "\n",
    "- re\n",
    "\n",
    "Spusťte následující buňku, modul re se importuje.\n",
    "\n",
    "**Poznámka:** Po každém zavření a otevření notebooku je nutné všechen kód (tj. i importování) spustit znovu. Výsledky sice zůstanou zobrazeny, obsah proměnných však v paměti nezůstává."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e316e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fffb90",
   "metadata": {},
   "source": [
    "## 5 Nejjednodušší tokenizátor\n",
    "\n",
    "Nejjednodušší tokenizátor v Pythonu naprogramujeme na třech řádcích díky metodě `split`. Text rozdělíme na slova pomocí mezer.\n",
    "\n",
    "Nejprve vyzveme uživatele k zadání textu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb852ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zadejte text pro tokenizaci:       V polovině ledna se v médiích objevila zpráva, že předsedkyně Poslanecké sněmovny Markéta Pekarová Adamová shání stážistu. „Stážistce či stážistovi nabízíme aktivní zapojení do práce v oblasti mezinárodních vztahů a diplomatických aktivit předsedkyně, seznámení se s chodem kanceláře předsedkyně a také s prostorami a fungováním Poslanecké sněmovny,“ stojí v inzerátu.\n"
     ]
    }
   ],
   "source": [
    "text = input('Zadejte text pro tokenizaci: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f497c8",
   "metadata": {},
   "source": [
    "Text poté tokenizujeme pomocí metody `split`. Pokud této metodě nespecifikujeme, podle čeho má text rozdělit, použije k rozdělení slov mezeru. V tomto případě je toto chování, které požadujeme, argumenty metody tedy necháme prázdné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3127f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efaa69a",
   "metadata": {},
   "source": [
    "Tokenizovaný text vypíšeme.\n",
    "\n",
    "**Poznámka:** Tímto způsobem lze text vypsat pouze v prostředí Jupyter Notebook. Pokud budete programovat v jiných prostředích, použijte standardní `print(text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "153dbc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V',\n",
       " 'polovině',\n",
       " 'ledna',\n",
       " 'se',\n",
       " 'v',\n",
       " 'médiích',\n",
       " 'objevila',\n",
       " 'zpráva,',\n",
       " 'že',\n",
       " 'předsedkyně',\n",
       " 'Poslanecké',\n",
       " 'sněmovny',\n",
       " 'Markéta',\n",
       " 'Pekarová',\n",
       " 'Adamová',\n",
       " 'shání',\n",
       " 'stážistu.',\n",
       " '„Stážistce',\n",
       " 'či',\n",
       " 'stážistovi',\n",
       " 'nabízíme',\n",
       " 'aktivní',\n",
       " 'zapojení',\n",
       " 'do',\n",
       " 'práce',\n",
       " 'v',\n",
       " 'oblasti',\n",
       " 'mezinárodních',\n",
       " 'vztahů',\n",
       " 'a',\n",
       " 'diplomatických',\n",
       " 'aktivit',\n",
       " 'předsedkyně,',\n",
       " 'seznámení',\n",
       " 'se',\n",
       " 's',\n",
       " 'chodem',\n",
       " 'kanceláře',\n",
       " 'předsedkyně',\n",
       " 'a',\n",
       " 'také',\n",
       " 's',\n",
       " 'prostorami',\n",
       " 'a',\n",
       " 'fungováním',\n",
       " 'Poslanecké',\n",
       " 'sněmovny,“',\n",
       " 'stojí',\n",
       " 'v',\n",
       " 'inzerátu.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecdc849",
   "metadata": {},
   "source": [
    "Jak si můžeme všimnout, text se tokenizoval, dokonce jsme se díky metodě `split` zbavili počátečních mezer. Hlavní problém je ale s interpunkcí. V našem tokenizátoru určitě nebudeme chtít mít interpunkci jako součást předchozího slova, samotná metoda `split` nám tedy nebude stačit.\n",
    "\n",
    "V případě tokenizace není ideální ani uložení textu do proměnné přes metodu `input`. Zejména v případě, kdy budeme chtít tokenizovat dlouhé texty, se nám bude hodit jiný přístup, abychom text nemuseli kopírovat a následně jej vkládat.\n",
    "\n",
    "To stejné platí o přístupu k výslednému tokenizovanému textu. Může se nám hodit nechat jej v proměnné a dále ho zpracovávat, měli bychom ale být schopni výstup uložit do souboru.\n",
    "\n",
    "Než budeme upravovat náš tokenizátor, naučíme se, jak pomocí Pythonu pracovat se soubory. Ukážeme si přepsání obsahu souboru a přidání dalších řádků textu. Zjistíme, jak vytvořit úplně nový soubor. V další sekci si v krátkosti zopakujeme regulární výrazy.\n",
    "\n",
    "## 6 Práce se soubory\n",
    "\n",
    "### 6.1 Otevření souboru\n",
    "\n",
    "K otevření souboru v Pythonu slouží metoda `open`. Požaduje dva parametry:\n",
    "\n",
    "1. název souboru (pokud se soubor nachází ve stejné složce jako program, stačí pouze název s formátem, pokud se soubor nachází jinde, je nutné specifikovat celou cestu),\n",
    "2. mód, v jakém se soubor otevře (v našem případě `r`= read = ke čtení).\n",
    "\n",
    "Pokud si budete chtít otevření souboru vyzkoušet, zkontrolujte, že do příkazu níže zadáváte existující soubor s platnou cestou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190afda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('uryvek.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cec7c9",
   "metadata": {},
   "source": [
    "Všimněte si, že metoda `open` sice otevře daný soubor a uloží jej do proměnné, nevypíše ale obsah souboru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59cb42d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='uryvek.txt' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfafae",
   "metadata": {},
   "source": [
    "### 6.2 Přečtení souboru\n",
    "\n",
    "K výpisu obsahu proměnné musíme použít metodu `read`, která přečte celý soubor (případně metodu `readlines`, která čte po jednom řádku)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "856d4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = txt.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd63ca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zprava:\\n\\n      V polovině ledna se v médiích objevila zpráva, že předsedkyně Poslanecké sněmovny Markéta Pekarová Adamová shání stážistu. „Stážistce či stážistovi nabízíme aktivní zapojení do práce v oblasti mezinárodních vztahů a diplomatických aktivit předsedkyně, seznámení se s chodem kanceláře předsedkyně a také s prostorami a fungováním Poslanecké sněmovny,“ stojí v inzerátu.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e2e251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3 = txt.readlines(1) #přečti jeden řádek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1986016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zprava:\\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840743b",
   "metadata": {},
   "source": [
    "### 6.3 Zavření souboru\n",
    "\n",
    "K zavření souboru slouží metoda `close`. Zavírání souborů je dobrou praxí, která nám zaručí, že si nepoškodíme soubory, se kterými pracujeme. Více na [Stack Overflow](https://stackoverflow.com/questions/7395542/is-explicitly-closing-files-important).\n",
    "\n",
    "**Poznámka:** Pokud proměnnou přepíšete, tj. proměnná již neobsahuje samotný soubor, ale např. text uložený v řetězci, zavřít soubor vám nepůjde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611e9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bbc91",
   "metadata": {},
   "source": [
    "#### 6.3.1 With open\n",
    "\n",
    "Metoda `with open` se o zavření souboru postará automaticky. Více třeba ve vláknu na [Stack Overflow](https://stackoverflow.com/questions/9282967/how-to-open-a-file-using-the-open-with-statement).\n",
    "\n",
    "### 6.4 Zápis do již existujícího souboru\n",
    "\n",
    "Pokud chceme do souboru i zapisovat, musíme změnit mód, ve kterém soubor otevřeme. V sekci 5.1 jsme použili mód `r` (ke čtení). Pro zápis si můžeme vybrat ze dvou módů:\n",
    "\n",
    "1. `a` = append = další text připojí na konec souboru\n",
    "2. `w` = write = přepíše existující obsah souboru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6acb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('uryvek.txt', 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161b030",
   "metadata": {},
   "source": [
    "Po použití těchto dvou módů můžeme použít metodu `write` k zápisu dalších řetězců do souboru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e78f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.write('Nový text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e574e72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zprava:\\n\\n      V polovině ledna se v médiích objevila zpráva, že předsedkyně Poslanecké sněmovny Markéta Pekarová Adamová shání stážistu. „Stážistce či stážistovi nabízíme aktivní zapojení do práce v oblasti mezinárodních vztahů a diplomatických aktivit předsedkyně, seznámení se s chodem kanceláře předsedkyně a také s prostorami a fungováním Poslanecké sněmovny,“ stojí v inzerátu.\\n\\nNový text'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6e9d84",
   "metadata": {},
   "source": [
    "### 6.5 Vytvoření nového souboru\n",
    "\n",
    "K vytvoření nového souboru neexistuje specifická funkce, použijeme metodu `open` s některým ze třech módů: `x`, `a`, `w`. \n",
    "\n",
    "S `a` a `w` jsme se setkali v předchozí sekci. Jejich použití od nového módu `x` = create se liší v chybových hláškách. Módy `a` a `w` vytvoří nový soubor pouze, pokud již neexistuje. Pokud soubor se stejným jménem existuje, nestane se nic, ale nedostanete ani chybovou hlášku. Oproti tomu mód `x` vytvoří nový soubor pouze pokud soubor se stejným jménem již neexistuje. Pokud takový soubor existuje, dostanete chybovou hlášku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a73bb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('uryvek2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ae3fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('uryvek2.txt', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3a0e1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'uryvek2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28428/178794835.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uryvek2.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'uryvek2.txt'"
     ]
    }
   ],
   "source": [
    "txt = open('uryvek2.txt', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957ac2b",
   "metadata": {},
   "source": [
    "Přehled všech metod a módů práce se souboru naleznete např. na [Geeks for Geeks](https://www.geeksforgeeks.org/writing-to-file-in-python/).\n",
    "\n",
    "## 7 Regulární výrazy\n",
    "\n",
    "Regulární výrazy slouží jako vzor pro vyhledávání v textu. V Pythonu díky knihovně re a různým funkcím můžeme textové řetězce nejen vyhledávat, ale i modifikovat nebo je nahrazovat za jiné řetězce. V tokenizátoru využijeme hlavně vyhledávání, pokud budeme chtít nalézt např. interpunkci.\n",
    "\n",
    "K vyhledávání slouží v Pythonu funkce `search`. Tato funkce požaduje dva parametry, regulární výraz a text, ve kterém se má vyhledávat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a595d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Jasno nebo skoro jasno.'\n",
    "sent2 = 'Maximální teploty 10 až 14 °C. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed41a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.search('\\d', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4759b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e205a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.search('\\d', sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19d88a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(18, 19), match='1'>\n"
     ]
    }
   ],
   "source": [
    "print(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f28eaf",
   "metadata": {},
   "source": [
    "Pokud funkce `search` nenalezne text, který by korespondoval s regulárním výrazem, vrátí hodnotu `None`. Pokud naopak nalezne shodu, vrátí index prvního výskytu (`span`) a kolikrát se daný výraz v textu vyskytuje (`match`). V případě, že budeme chtít nalézt všechny textové řetězce, nejenom první, musíme použít funkci `findall`.\n",
    "\n",
    "Efektivnějším způsobem, jak pracovat s regulárními výrazy, je uložit si je do proměnné. A to zejména, pokud stejné výrazy používáme na různých místech v kódu. Výraz pak v řešení změníme pouze jednou. K tomu slouží funkce `compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2c03da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feb8affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = re.findall(pattern, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b654d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '0', '1', '4']\n"
     ]
    }
   ],
   "source": [
    "print(reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e580f",
   "metadata": {},
   "source": [
    "Další funkce naleznete v [dokumentaci ke kni](), další informace a užitečné odkazy naleznete v sekci 3 tohoto notebooku.\n",
    "\n",
    "## 8 Tokenizátor s použitím regulárních výrazů\n",
    "\n",
    "V této sekci budete mít za úkol naprogramovat tokenizátor používající regulární výrazy pro vybrané problémy tokenizace. Než se pustíte do programování, připomeňte si práci s knihovnou re a regulárními výrazy (užitečné odkazy jsou k dispozici v sekci 3 tohoto notebooku).\n",
    "\n",
    "**Úkol:** Vytvořte program, který načte data ze souboru, tokenizuje text a výsledek vrátí ve vámi zvolené formě (uložení do souboru, datový typ vhodný k dalšímu zpracování, ...).\n",
    "\n",
    "Pracujte buď s ukázkovým textem, nebo si najděte vlastní. Vyberte ale vhodný text, který obsahuje alespoň přímou řeč, závorky, čísla s desetinnou čárkou/tečkou, zkratky, případně další \"problémy\", které si vyberete. Text můžete slepit i z vícero zdrojů.\n",
    "\n",
    "Použijte regulární výrazy k nalezení těchto \"problémů\" a rozhodněte se, jak je budete řešit (např. budou závorky a uvozovky samostatné tokeny?). Váš přístup musí být konstatní pro celý text.\n",
    "\n",
    "Program vhodně rozdělte na funkce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ffa9a",
   "metadata": {},
   "source": [
    "<details> \n",
    "    <summary>Pokud nevíte, jak začít, klikněte na tento text pro <b>zobrazení nápovědy</b>.</summary>\n",
    "    <p>Vytvořte funkci, která otevře soubor a uloží obsah souboru (text) do proměnné.</p>\n",
    "    <p>Rozdělte text pomocí mezer a metody split na jednotlivé tokeny.</p>\n",
    "    <p>Použijte regulární výrazy k nalezení interpunkce, závorek, uvozovek apod. v tokenech.</p>\n",
    "    <p>K oddělení např. interpunkce od slov můžete použít řezy. Více informací o řezech naleznete třeba na <a name=\"https://stackoverflow.com/questions/509211/understanding-slice-notation\">Stack Overflow</a>.</p>\n",
    "    <p>Rozhodněte se, jestli necháte výsledný tokenizovaný text uložený v proměnné, nebo jej uložíte do souboru.</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2f79f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\" Otevři textový soubor a obsah ulož do proměnné. Znaky pro nový řádek nahraď za mezery.\"\"\"\n",
    "\n",
    "    with open(data, 'r') as raw: #otevři textový soubor\n",
    "        raw = raw.read() #ulož obsah textového souboru do proměnné raw\n",
    "        raw = raw.replace('\\n', ' ') #nahraď znak pro nový řádek za mezeru\n",
    "        \n",
    "    return raw #vrať proměnnou data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac1dfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation(data):\n",
    "    \"\"\" Rozděl text podle mezer a tokenizuj interpunkci na konci vět. \"\"\"\n",
    "    \n",
    "    #Regulární výrazy\n",
    "    abbr = re.compile(r'\\b(?:[A-Za-z]\\.)+|\\b(?:[A-Z][a-z]{1,2}\\.)+|(?:[A-Z]\\.)+') #zkratky\n",
    "    ords = re.compile(r'\\d+\\.') #řadové číslovky\n",
    "    end_punct = re.compile(r'[\\.\\?\\!\\:\\,]$') #interpunkce na konci vět\n",
    "\n",
    "    #Tokenizace\n",
    "    data = data.split() #rozděl slova podle mezer\n",
    "    \n",
    "    for tok in data: #pro každý token v seznamu\n",
    "        where = data.index(tok) #ulož index tokenu v seznamu\n",
    "        \n",
    "        if re.search(end_punct, tok) and len(tok) > 1 and not re.search(abbr, tok) and not re.search(ords, tok):\n",
    "            #vyhledej interpunkci na konci vět a čárky za slovy\n",
    "            token1 = tok[:-1] #ulož samotné slovo\n",
    "            end = tok[-1] #ulož samotné interpunkční znaménko\n",
    "            data.remove(tok) #odstraň ze seznamu původní token\n",
    "            data.insert(where, token1) #vlož do seznamu samotné slovo\n",
    "            data.insert(where+1, end) #za samotné slovo v seznamu vlož samotné interpunkční znaménko\n",
    "            \n",
    "    return data #vrať tokenizovaný text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c1d454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brackets(data):\n",
    "    \"\"\" Tokenizuj závorky, uvozovky a další interpunkci jako samostatné tokeny \"\"\"\n",
    "    \n",
    "    #Regulární výrazy\n",
    "    end_br = re.compile(r'[\\.\\?\\!\\,]+[\\)\\]\\}\\'\\\"\\“]') #interpunkce uvnitř závorek a uvozovek\n",
    "    brq_front = re.compile(r'^[\\\"\\[\\(\\{\\'\\„]') #levé závorky a uvozovky\n",
    "    brq_back = re.compile(r'\\\"|\\]|\\)|\\}|\\'|\\“') #pravé závorky a uvozovky\n",
    "    \n",
    "    for tok in data: #pro každý token v seznamu\n",
    "        where = data.index(tok) #ulož index tokenu v seznamu\n",
    "\n",
    "        if re.search(end_br, tok) and len(tok) > 1:\n",
    "            #vyhledej interpunkční znaménka uvnitř závorek nebo uvozovek\n",
    "            token1 = tok[:-2] #ulož samotné slovo\n",
    "            end1 = tok[-2] #ulož samotné interpunkční znaménko\n",
    "            end2 = tok[-1] #ulož samotnou závorku nebo samotné uvozovky\n",
    "            data.remove(tok) #odstraň ze seznamu původní token\n",
    "            data.insert(where, token1) #na index původního tokenu ulož samotné slovo\n",
    "            data.insert(where+1, end1) #na následující index ulož samotné interpunkční znaménko\n",
    "            data.insert(where+2, end2) #na následující index ulož samotnou závorku nebo samotné uvozovky\n",
    "            \n",
    "        elif re.search(brq_front, tok) and len(tok) > 1:\n",
    "            #vyhledej levé závorky nebo uvozovky\n",
    "            token2 = tok[1:] #ulož slovo za závorkou nebo uvozovkami\n",
    "            brq = tok[0] #ulož samotnou závorku nebo uvozovky\n",
    "            data.remove(tok) #odstraň ze seznamu původní token\n",
    "            data.insert(where, brq) #na index původního tokenu ulož samotnou závorku nebo samotné uvozovky\n",
    "            data.insert(where+1, token2) #na následující index ulož samotné slovo\n",
    "        \n",
    "        elif re.search(brq_back, tok) and len(tok) > 1:\n",
    "            #vyhledej pravé závorky nebo uvozovky\n",
    "            token1 = tok[:-1] #ulož samotné slovo před závorkou nebo uvozovkami\n",
    "            brq = tok[-1] #ulož samotnou závorku nebo samotné uvozovky\n",
    "            data.remove(tok) #odstraň ze seznamu původní token\n",
    "            data.insert(where, token1) #na index původního tokenu ulož samotné slovo\n",
    "            data.insert(where+1, brq) #na následující index ulož samotnou závorku nebo samotné uvozovky\n",
    "                        \n",
    "    return data #vrať tokenizovaný text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a4dffeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenized_text(tokenized_text, file_name):\n",
    "    \"\"\" Ulož tokenizovaný text do souboru tokenized.txt \"\"\"\n",
    "    \n",
    "    with open(file_name, 'a') as txt: #vytvoř nový soubor tokenized.txt v módu append\n",
    "        for tok in tokenized_text: #každý token v seznamu\n",
    "            txt.write(tok + '\\n') #zapiš do souboru na nový řádek\n",
    "            \n",
    "    return 0 #úspěšné ukončení fce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4adb2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\" Tokenizuj text a ulož jej do souboru \"\"\"\n",
    "    text = prepare_data(text) #zavolej funkci prepare_data\n",
    "    print('Příprava dat...')\n",
    "    text = punctuation(text) #zavolej funkci punctuation\n",
    "    print('Tokenizace...')\n",
    "    text = brackets(text) #zavolej funkci brackets\n",
    "    save_tokenized_text(text, 'tokenized.txt') #zavolej funkci save_tokenized_text\n",
    "    print('Ukládání tokenizovaného textu do souboru tokenized.txt...')\n",
    "    print('Hotovo.')\n",
    "    return 0 #úspěšné ukončení fce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b6f1ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Příprava dat...\n",
      "Tokenizace...\n",
      "Ukládání tokenizovaného textu do souboru tokenized.txt...\n",
      "Hotovo.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea64e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
