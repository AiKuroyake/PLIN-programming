{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d16dca92",
   "metadata": {},
   "source": [
    "# CMU Pronouncing Dictionary\n",
    "\n",
    "V tomto úkolu si vyzkoušíme práci s grafickým rozhraním Jupyter Notebook, které je vhodné pro postupné spouštění kódu. Naučíme se importovat knihovny do Pythonu a dále s nimi pracovat. Nejdůležitější knihovnou pro nás v tomto notebooku bude NLTK. V rámci této knihovny použijeme slovník CMU Pronouncing Dictionary, pomocí kterého budeme schopni vypsat výslovnost anglické věty. Pokračovat budeme s hledáním slov, která lze vyslovit dvěma a více způsoby.\n",
    "\n",
    "Poznámka: Kvůli možné záměně slovníku jako seřazeného seznamu slovní zásoby a slovníku jako datového typu v Pythonu se v tomto notebooku pro datové typy používají anglické názvy (tj. dictionary pro slovník, list pro seznam, tuple pro n-tici apod.).\n",
    "\n",
    "## 1. S čím budeme pracovat\n",
    "\n",
    "### 1.1 Jupyter Notebook\n",
    "\n",
    "Právě se nacházíte v prostředí Jupyter Notebook. Jedná se o webovou aplikaci umožňující spouštět tzv. notebooky, dokumenty obsahující jak spustitelný kód (v našem případě v programovacím jazyce Python), tak textové prvky jako například odstavce, odkazy, obrázky, grafy, rovnice. Největší výhodou těchto notebooků je právě možnost kombinovat kód a prostý text, což umožňuje přímo komentovat jednotlivé kroky programu bez nutnosti tyto komentáře ukládat do samostatného souboru.\n",
    "\n",
    "Více informací na [Project Jupyter](https://jupyter.org/) a [Jupyter Notebook dokumentaci](https://jupyter-notebook.readthedocs.io/en/stable/).\n",
    "\n",
    "### 1.2 NLTK\n",
    "\n",
    "NLTK (Natural Language Toolkit) je knihovna pro programovací jazyk Python. Knihovny jsou zaměřené na různé oblasti, například datovou vědu, strojové učení, vizualizaci dat a poskytují znovupoužitelný kód, nejčastěji ve formě funkcí. Programátor pak není nucen pokaždé vymýšlet vlastní řešení pro běžný problém, ale zakomponuje do svého programu část z nějaké knihovny, kterou potřebuje. Knihovny navíc bývají optimalizovány tak, aby výsledný kód fungoval rychleji nebo nezabíral příliš výpočetní paměti, proto v mnoha případech ani není na místě snažit se o napsání vlastního řešení, pokud známe vhodnou knihovnu pro daný problém.\n",
    "\n",
    "Pomocí NLTK zpracováváme přirozený jazyk. Kromě užitečných funkcí na tokenizaci, tagování, parsování, stemování apod. NLTK obsahuje velké množství korpusů a lexikálních zdrojů (např. WordNety). Nevýhodou NLTK je její zaměření na angličtinu.\n",
    "\n",
    "Více informací na [NLTK dokumentaci](https://www.nltk.org/index.html), [NLTK Wiki](https://github.com/nltk/nltk/wiki) a [NLTK Book](https://www.nltk.org/book/).\n",
    "\n",
    "### 1.3 CMU Pronouning Dictionary\n",
    "\n",
    "Carnegie Mellon University Pronouncing Dictionary (zkráceně CMU Dict) je slovník, který obsahuje přepis výslovnosti anglických slov. Zaměřuje se na výslovnost angličtiny Severní Ameriky. CMU Dict obsahuje kolem 134 000 slov, ke každému slovu je přiřazen alespoň jeden výslovnostní přepis. Narozdíl od běžných fonetických přepisů, na které jsme zvyklí, CMU Dict používá ARPAbet, fonetickou transkripci, která je vhodná pro zpracování na počítači. Obsahuje totiž pouze znaky ASCII. CMU Dict je navíc zabudován do knihovny NLTK, nemusíme tedy data složitě stahovat, na vše nám bude stačit Python.\n",
    "\n",
    "Více informací na [CMU Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict) a [ARPAbet](https://en.wikipedia.org/wiki/ARPABET).\n",
    "\n",
    "### 1.4 Matplotlib\n",
    "\n",
    "Co je to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44e7f4",
   "metadata": {},
   "source": [
    "## 2. Instalace nltk, cmu dict, apod.\n",
    "\n",
    "Popsat pro vse zvlast\n",
    "\n",
    "## 3. Import knihoven a modulů\n",
    "\n",
    "Než budeme moct začít s psaním programu, musíme importovat všechny knihovny a moduly, které budeme potřebovat. Patří mezi ně:\n",
    "\n",
    "- nltk\n",
    "- re\n",
    "- string\n",
    "- word_tokenize\n",
    "- defaultdict\n",
    "\n",
    "Spusťte následující buňku. Knihovny a moduly se vám importují.\n",
    "\n",
    "Poznámka: Po každém otevření notebooku je nutné kód spustit znovu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087f5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6432f3",
   "metadata": {},
   "source": [
    "## 4. Struktura slovníku CMU Dict\n",
    "\n",
    "Nejprve si uložíme celý slovník CMU Dict do proměnné `entries`. Ke slovníku poté budeme přistupovat přes tuto proměnnou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a90ac498",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14dc062",
   "metadata": {},
   "source": [
    "Než začneme programovat, měli bychom vědět, jak je slovník strukturovaný. \n",
    "\n",
    "**Úkol 1:** Pomocí příkazu `print` vypište celý slovník."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2c04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', ['AH0']), ('a.', ['EY1']), ('a', ['EY1']), ...]\n"
     ]
    }
   ],
   "source": [
    "print(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2656d11",
   "metadata": {},
   "source": [
    "Slovník se nám sice nevypíše celý, ale předchozí příkaz nám pomůže vypozorovat alespoň 4 zásadní věci, které nám ulehčí programování:\n",
    "\n",
    "1. Slovník je uložen v datovém typu list,\n",
    "2. jednotlivá slova jsou uložena v datovém typu tuple,\n",
    "3. výslovnost jednotlivých slov je uložena v datovém typu list,\n",
    "4. slovník je seřazen podle abecedy.\n",
    "\n",
    "Jelikož datovým typem slovníku je list, k jednotlivým slovům můžeme přistupovat i přes indexy. Následující tři úkoly se týkají indexace.\n",
    "\n",
    "**Úkol 2:** Vypište, kolik položek má slovník celkem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146676be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133737\n"
     ]
    }
   ],
   "source": [
    "print(len(entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95691f76",
   "metadata": {},
   "source": [
    "**Úkol 3:** Vyberte si číslo z intervalu 0 až celkový počet položek a vypište slovo, které se ve slovníku nachází pod tímto indexem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc00f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('antifungal', ['AE2', 'N', 'T', 'IY2', 'F', 'AH1', 'NG', 'G', 'AH0', 'L'])\n"
     ]
    }
   ],
   "source": [
    "print(entries[4567])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd2166",
   "metadata": {},
   "source": [
    "**Úkol 4:** Vypište slovo, které se nachází pod indexem 33330."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856445e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dog', ['D', 'AO1', 'G'])\n"
     ]
    }
   ],
   "source": [
    "print(entries[33330])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c9291",
   "metadata": {},
   "source": [
    "Minimálně u čtvrtého úkolu se nám podařilo vypsat slovo skládající se z více než jednoho písmene. Můžeme si všimnout, že:\n",
    "\n",
    "- Pár slovo-výslovnost je uložený v datovém typu tuple,\n",
    "- slovo je vždy psáno s malými písmeny,\n",
    "- výslovnost slova je uložena v datovém typu list,\n",
    "- každý prvek v listu u výslovnosti odpovídá jednomu fonému,\n",
    "- čísla u fonémů značí přízvuk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce0a92",
   "metadata": {},
   "source": [
    "## 5. Výslovnost anglické věty\n",
    "\n",
    "Teď již víme, jak CMU Dict vypadá, a můžeme začít programovat. V této sekci napíšeme jednoduchý program, který vyzve uživatele, aby zadal anglickou větu, a poté vypíše výslovnost všech slov této věty. \n",
    "\n",
    "**Úkol 5:** Vyzvěte uživatele, aby zadal anglickou větu. Tuto větu uložte do proměnné `sent`. Po spuštění kódu vás notebook požádá o anglickou větu. Vyberte si libovolnou větu v angličtině, mějte ale na paměti, že ve slovníku je pouze 134 000 slov, volte proto slova běžné slovní zásoby.\n",
    "\n",
    "V tomto řešení budeme pracovat s větou \"I will meet you tomorrow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5c23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an English sentence: I will meet you tomorrow.\n"
     ]
    }
   ],
   "source": [
    "sent = input('Enter an English sentence: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a77c3",
   "metadata": {},
   "source": [
    "Se zadanou větou nemůžeme pracovat jen tak, musíme ji tzv. normalizovat. Všechna velká písmena převedeme na malá, větu očistíme od interpunkce a na konec ji tokenizujeme.\n",
    "\n",
    "Pro normalizaci vytvoříme funkci `normalize`, která bude brát parametr `sentence` (větu, kterou zadal uživatel). Vracet bude tokenizovanou větu, kterou později uložíme do proměnné.\n",
    "\n",
    "**Úkol 6:**\n",
    "\n",
    "1. Vytvořte funkci `normalize`, která požaduje parametr `sentence`,\n",
    "2. zbavte se všech velkých písmen,\n",
    "3. odstraňte interpunkci (řešení používá knihovnu `re`, ale můžete přijít i na jiný způsob bez regulárních výrazů),\n",
    "4. vraťte normalizovanou větu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca3467bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentence):\n",
    "    \"\"\" Remove upper-case letters and punctuation, then tokenize the text \"\"\"\n",
    "    \n",
    "    sentence = sentence.lower() #lower-case everything\n",
    "    regex = re.compile('[{}]'.format((re.escape(string.punctuation)))) #regex pattern\n",
    "    sentence = regex.sub('', sentence) #remove punctuation from a string\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb5412d",
   "metadata": {},
   "source": [
    "**Úkol 7:** \n",
    "\n",
    "1. Normalizujte větu `sent` a uložte ji do nové proměnné `sent_norm`,\n",
    "2. vypište normalizovanou větu,\n",
    "3. zkontrolujte výstup, vypsat by se měl string s malými písmeny bez interpunkce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c98b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i will meet you tomorrow\n"
     ]
    }
   ],
   "source": [
    "sent_norm = normalize(sent) #save the normalized sentence into a variable\n",
    "print(sent_norm) #print the normalized sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d5a2f",
   "metadata": {},
   "source": [
    "**Úkol 8:**\n",
    "\n",
    "1. Vytvořte funkci `tokenize`, která požaduje parametr `sentence`,\n",
    "2. tokenizujte větu pomocí tokenizátoru `word_tokenize`, který jsme naimportovali na začátku notebooku z knihovny `NLTK`,\n",
    "3. vraťte tokenizovanou větu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694ce0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    \"\"\" Tokenize the sentence \"\"\"\n",
    "    \n",
    "    sentence = word_tokenize(sentence) #tokenize the sentence\n",
    "    \n",
    "    return sentence #return the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f072fd",
   "metadata": {},
   "source": [
    "**Úkol 9:**\n",
    "\n",
    "1. Tokenizujte větu `sent_norm` a uložte ji do nové proměnné `sent_tok`,\n",
    "2. vypište tokenizovanou větu,\n",
    "3. zkontrolujte výstup, vypsat by se měl list s jednotlivými slovy jako prvky listu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19dfa5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'will', 'meet', 'you', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "sent_tok = tokenize(sent_norm) #save the tokenized sentence into a variable\n",
    "print(sent_tok) #print the tokenized sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c5797",
   "metadata": {},
   "source": [
    "Nyní máme větu připravenou a můžeme pro každé slovo najít výslovnost ve CMU Dict. \n",
    "\n",
    "**Úkol 10:**\n",
    "\n",
    "1. Vytvořte funkci `pronunciation`, která požaduje parametr `sentence`,\n",
    "2. připravte prázdnou proměnnou `pron`, kam později uložíte všechny způsoby výslovnosti všech slov v proměnné `sent_tok` (o vhodném datovém typu rozhodněte),\n",
    "3. iterujte přes všechna slova ve slovníku CMU Dict, pokud se slovo nachází i v listu `sent_tok`, uložte jeho výslovnost do předpřipravené proměnné `pron` (dopředu přemýšlejte o tom, jak později vypíšete výslovnost jednotlivých slov, vhodně rozhodněte, jakým způsobem jednotlivé fonémy uložíte),\n",
    "4. vraťte proměnnou `pron`, která obsahuje výslovnost jednotlivých slov.\n",
    "\n",
    "V řešení úkolů 10 a 11 je rovnou naprogramované uložení výslovnosti s mezerami mezi fonémy a oddělením slov pomocí | (úkol navíc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd660546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronunciation(sentence):\n",
    "    \"\"\" For each word in a sentence find its pronunciation in the CMU dict \"\"\"\n",
    "    pron = [] #an empty list for pronunciation\n",
    "    \n",
    "    for entry in entries: #go through every entry in CMU Dict\n",
    "        for tok in sentence: #go through every token in the tokenized sentence\n",
    "            if entry[0] == tok: #if the word in CMU Dict is the same as the token in the tokenized sentence\n",
    "                pron.append(' '.join(p for p in entry[1])) #save the pronunciation as a string\n",
    "    \n",
    "    return pron #return the pronunciation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33554955",
   "metadata": {},
   "source": [
    "**Úkol 11:**\n",
    "\n",
    "1. Uložte výslovnost všech slov do proměnné `sent_pron`,\n",
    "2. vypište výslovnost všech slov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24e92093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AY1 | M IY1 T | T AH0 M AA1 R OW2 | T UW0 M AA1 R OW2 | W IH1 L | W AH0 L | Y UW1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pron = pronunciation(sent_tok) #save the pronunciation into a variable\n",
    "' | '.join(tok for tok in sent_pron) #print the pronunciation of the sentence, separate words by |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac730f26",
   "metadata": {},
   "source": [
    "**Úkol navíc:** V ARPAbet zápisu se fonémy oddělují mezerou. Zkuste funkci `pronunciation` a následně výpis výslovnosti všech slov upravit tak, aby jednotlivé fonémy byly odděleny mezerou. Pro slova vyberte jiný oddělovač."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c497c6",
   "metadata": {},
   "source": [
    "V závislosti na tom, jakou větu jste zvolili, jste buď našli nebo nenašli slova, která lze vyslovit vícero způsoby. V řešení pracujeme s větou \"I will meet you tomorrow.\", u které si můžeme všimnout, že nesedí počet slov ve výslovnostním přepisu. Program nám našel dvě slova (tomorrow a will), která se dají vyslovit více než jedním způsobem.\n",
    "\n",
    "V další sadě úkolů se budeme zaobírat právě tímto problémem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d5530",
   "metadata": {},
   "source": [
    "## 6. Slova, která lze vyslovit vícero způsoby\n",
    "\n",
    "V předchozí sekci jsme narazili na slova, která se dají vyslovit dvěma různými způsoby. V následujících úkolech si vyzkoušíme, jak vyhledat pouze tato specifická slova a vypsat je se všemi výslovnostními variantami. \n",
    "\n",
    "Procvičíme si programování s datovým typem dictionary, jelikož je to jeden z nejpřehlednějších způsobů řešení tohoto problému. Práci si usnadníme pomocí modulu `defaultdict` a porovnáme ho s běžným dictionary.\n",
    "\n",
    "**Úkol 12:** Stejně jako v úkolu 5 požádejte uživatele o zadání anglické věty. Vstup uložte do proměnné `sent2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23772117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an English sentence: We are selling records tomorrow at the market.\n"
     ]
    }
   ],
   "source": [
    "sent2 = input('Enter an English sentence: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852bdd5",
   "metadata": {},
   "source": [
    "**Úkol 13:** Normalizujte větu v `sent2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b42c4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are selling records tomorrow at the market\n"
     ]
    }
   ],
   "source": [
    "sent2 = normalize(sent2) #normalize the sentence\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f67df52",
   "metadata": {},
   "source": [
    "**Úkol 14:** Tokenizujte normalizovanou větu `sent2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0640375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'selling', 'records', 'tomorrow', 'at', 'the', 'market']\n"
     ]
    }
   ],
   "source": [
    "sent2 = tokenize(sent2)\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708ce7d",
   "metadata": {},
   "source": [
    "V závislosti na výběru věty se může stát, že se nějaká slova budou ve větě opakovat. Našim cílem není vypsat úplně vše, ale pouze slova, která se vyslovují více než jedním způsobem, proto se můžeme zbavit duplicitních slov.\n",
    "\n",
    "**Úkol 15:** Zbavte se opakujících se slov ve větě `sent2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43194cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'market', 'we', 'records', 'at', 'selling', 'tomorrow', 'the', 'are'}\n"
     ]
    }
   ],
   "source": [
    "sent2 = set(sent2) #convert a list to a set to get rid of duplicates\n",
    "print(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd121aa",
   "metadata": {},
   "source": [
    "Nyní si připravíme funkci, která bude iterovat přes CMU Dict a hledat slova vyskytující se v naší větě. Jelikož budeme mít pro některá slova více než jednu možnou výslovnost, výsledky si uložíme do datového typu dictionary. Jako klíče použijeme slova, jejichž hodnoty budou všechny výslovnostní varianty.\n",
    "\n",
    "Pro tuto funkci je možné využít jak standardní dictionary, tak modul defaultdict, který ulehčuje přidávání klíčů do dictionary. V řešení si ukážeme jak variantu s běžným dictionary, tak variantu s modulem defaultdict.\n",
    "\n",
    "**Úkol 16:** \n",
    "\n",
    "1. Vytvořte funkci `pron_dict`, která vyžaduje parametr `sentence`,\n",
    "2. připravte prázdnou proměnnou datového typu dictionary, kam uložíte výsledky prohledávání CMU Dict (případně použijte defaultdict),\n",
    "3. všechna slova ve větě `sent2` vyhledejte ve CMU Dict,\n",
    "4. nalezená slova uložte do dictionary jako klíče, nalezené výslovnostní varianty uložte do dictionary jako hodnoty (o vhodných datových typech pro klíče a hodnoty rozhodněte),\n",
    "5. vraťte celý dictionary.\n",
    "\n",
    "Poznámka: V tuto chvíli se nezaobírejte, kolika způsoby je možné dané slovo vyslovit, do dictionary uložte i ta slova, která mají pouze jednu výslovnostní variantu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb35f6",
   "metadata": {},
   "source": [
    "Řešení s běžným dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e4dd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pron_dict(sentence):\n",
    "    \"\"\" Create a dictionary where words are keys and pronunciation is values\n",
    "        dictionary solution \"\"\"\n",
    "    sent_matches = dict() #create an empty dictionary\n",
    "    \n",
    "    for tok in sentence: #go through every token in the sentence\n",
    "        for entry in entries: #go through every entry in CMU Dict\n",
    "            if entry[0] == tok: #if the CMU Dict's entry is the same as the token in the sentence\n",
    "                if tok in sent_matches.keys(): #if the token already is in the dictionary\n",
    "                    sent_matches[tok].append(entry[1]) #append the pronunciation to previous ones\n",
    "                else: #if the token is not in the dictionary\n",
    "                    sent_matches[tok] = [entry[1]] #create a key-value pair where key is the token\n",
    "                                                   #and value is the pronunciation\n",
    "    return sent_matches #return the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b64238",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'market': [['M', 'AA1', 'R', 'K', 'AH0', 'T'], ['M', 'AA1', 'R', 'K', 'IH0', 'T']], 'we': [['W', 'IY1']], 'records': [['R', 'AH0', 'K', 'AO1', 'R', 'D', 'Z'], ['R', 'EH1', 'K', 'ER0', 'D', 'Z'], ['R', 'IH0', 'K', 'AO1', 'R', 'D', 'Z']], 'at': [['AE1', 'T']], 'selling': [['S', 'EH1', 'L', 'IH0', 'NG']], 'tomorrow': [['T', 'AH0', 'M', 'AA1', 'R', 'OW2'], ['T', 'UW0', 'M', 'AA1', 'R', 'OW2']], 'the': [['DH', 'AH0'], ['DH', 'AH1'], ['DH', 'IY0']], 'are': [['AA1', 'R'], ['ER0']]}\n"
     ]
    }
   ],
   "source": [
    "sent_pron_dict = pron_dict(sent2)\n",
    "print(sent_pron_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fa230",
   "metadata": {},
   "source": [
    "Řešení s modulem defaultdict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69bbe401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pron_defdict(sentence):\n",
    "    \"\"\" Create a dictionary where words are keys and pronunciation is values \n",
    "        defaultdict solution \"\"\"\n",
    "    sent_matches = defaultdict(list) #create a new defauldict object\n",
    "    \n",
    "    for tok in sentence: #go through every token in the sentence\n",
    "        for entry in entries: #go through every entry in CMU Dict\n",
    "            if entry[0] == tok: #if the CMU Dict's entry is the same as the token in the sentence\n",
    "                sent_matches[tok].append(entry[1]) #append the pronunciation (value) to the token (key)\n",
    "                \n",
    "    return sent_matches #return the defaultdict object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520350ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'market': [['M', 'AA1', 'R', 'K', 'AH0', 'T'], ['M', 'AA1', 'R', 'K', 'IH0', 'T']], 'we': [['W', 'IY1']], 'records': [['R', 'AH0', 'K', 'AO1', 'R', 'D', 'Z'], ['R', 'EH1', 'K', 'ER0', 'D', 'Z'], ['R', 'IH0', 'K', 'AO1', 'R', 'D', 'Z']], 'at': [['AE1', 'T']], 'selling': [['S', 'EH1', 'L', 'IH0', 'NG']], 'tomorrow': [['T', 'AH0', 'M', 'AA1', 'R', 'OW2'], ['T', 'UW0', 'M', 'AA1', 'R', 'OW2']], 'the': [['DH', 'AH0'], ['DH', 'AH1'], ['DH', 'IY0']], 'are': [['AA1', 'R'], ['ER0']]})\n"
     ]
    }
   ],
   "source": [
    "sent_pron_defdict = pron_defdict(sent2)\n",
    "print(sent_pron_defdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd36e0",
   "metadata": {},
   "source": [
    "Jak si můžeme všimnout, řešení pomocí defaultdict je o tři řádky kratší než řešení pomocí běžného dictionary. Při vytváření nového objektu defaultdict v příkazu `sent_matches = defaultdict(list)` říkáme, co se má nastavit jako defaultní hodnota pro neexistující klíče. Ve chvíli, kdy voláme klíče, které v defaultdict objektu nejsou, automaticky se vytvoří s danou defaultní hodnotou. V našem případě je to datový typ list. To nám umožňuje vynechat celou podmínku `if tok in sent_matches.keys()` ve funkci `pron_defdict` a rovnou ukládat hodnoty pomocí příkazu `sent_matches[tok].append(entry[1])`. Naproti tomu ale ve funkci `pron_dict` tato podmínka být musí, jinak by došlo k chybě `KeyError`.\n",
    "\n",
    "**Úkol 17:** Zjistěte, kolika způsoby se dá každé slovo v dictionary vyslovit. Na výstup vypište jak slovo, tak počet jeho výslovnostních variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23fcb44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market 2\n",
      "we 1\n",
      "records 3\n",
      "at 1\n",
      "selling 1\n",
      "tomorrow 2\n",
      "the 3\n",
      "are 2\n"
     ]
    }
   ],
   "source": [
    "for key, val in sent_pron_defdict.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866efa8",
   "metadata": {},
   "source": [
    "V závislosti na výběru vaší anglické věty narazíte na různý počet výslovnostních variant u různých slov.\n",
    "\n",
    "**Úkol 18:** \n",
    "\n",
    "1. Napište funkci `more_pron_dict` s parametrem `sent_pron`,\n",
    "2. vytvořte nový dictionary, do kterého uložíte pouze ta slova, která mají dvě a více výslovnostních variant,\n",
    "3. ponechte slova jako klíče a výslovnostní varianty jako hodnoty,\n",
    "4. vraťte dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e017fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_pron_dict(sent_pron):\n",
    "    \"\"\" Create a new dictionary and store the words we can pronounce differently there \"\"\"\n",
    "    pron = {}\n",
    "    \n",
    "    for key, val in sent_pron.items():\n",
    "        if len(val) > 1:\n",
    "            pron[key] = val\n",
    "            \n",
    "    return pron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3e042",
   "metadata": {},
   "source": [
    "**Úkol 19:** Nový dictionary uložte do proměnné a vypište."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22671efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'market': [['M', 'AA1', 'R', 'K', 'AH0', 'T'], ['M', 'AA1', 'R', 'K', 'IH0', 'T']], 'records': [['R', 'AH0', 'K', 'AO1', 'R', 'D', 'Z'], ['R', 'EH1', 'K', 'ER0', 'D', 'Z'], ['R', 'IH0', 'K', 'AO1', 'R', 'D', 'Z']], 'tomorrow': [['T', 'AH0', 'M', 'AA1', 'R', 'OW2'], ['T', 'UW0', 'M', 'AA1', 'R', 'OW2']], 'the': [['DH', 'AH0'], ['DH', 'AH1'], ['DH', 'IY0']], 'are': [['AA1', 'R'], ['ER0']]}\n"
     ]
    }
   ],
   "source": [
    "diff_pron = more_pron_dict(sent_pron_defdict)\n",
    "print(diff_pron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b009d6",
   "metadata": {},
   "source": [
    "Výpis takto můžeme nechat, došli jsme ke správnému řešení. Je ale těžké se ve výsledcích vyznat, proto upravíme výstup, aby byl přehlednější.\n",
    "\n",
    "**Úkol 20:** Vytvořte funkci `pron_no_list` s parametrem `diff_pron`, ve které se zbavíte jednotlivých listů u výslovnostních variant. Spojte prvky listu do stringu. Např. slovo \"are\" tedy nebude vypadat jako `'are': [['AA1', 'R'], ['ER0']]`, ale jako `'are': ['AA1 R', 'ER0']`. Na výstupu zachovejte datový typ dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76eb2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pron_no_list(diff_pron):\n",
    "    \"\"\" Create a new dictionary. In values store a list of strings with phones \"\"\"\n",
    "    pron_no_l = defaultdict(list)\n",
    "\n",
    "    for key, val in diff_pron.items():\n",
    "        for words in val:\n",
    "            pron_no_l[key].append(' '.join(w for w in words))\n",
    "    \n",
    "    return pron_no_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28283224",
   "metadata": {},
   "source": [
    "**Úkol 21:** Nový dictionary uložte do proměnné a vypište."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aadab43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'market': ['M AA1 R K AH0 T', 'M AA1 R K IH0 T'], 'records': ['R AH0 K AO1 R D Z', 'R EH1 K ER0 D Z', 'R IH0 K AO1 R D Z'], 'tomorrow': ['T AH0 M AA1 R OW2', 'T UW0 M AA1 R OW2'], 'the': ['DH AH0', 'DH AH1', 'DH IY0'], 'are': ['AA1 R', 'ER0']})\n"
     ]
    }
   ],
   "source": [
    "diff_pron_no_lst = pron_no_list(diff_pron)\n",
    "print(diff_pron_no_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9ecec",
   "metadata": {},
   "source": [
    "V tuto chvíli dictionary výsledek vypadá mnohem lépe, k ideálnímu výstupu nám už ale zbývá pouze jeden krok. Slova budeme vypisovat ve formátu `slovo: výslovnost1 | výslovnost2 | výslovnost3`. K tomu nám bude stačit jeden for cyklus, [metoda join](https://www.geeksforgeeks.org/python-string-join-method/) a tzv. [list comprehension](https://www.geeksforgeeks.org/python-list-comprehension/).\n",
    "\n",
    "K tomuto kroku nemusíte vymýšlet kód, následující buňku pouze spusťte a podívejte se na výsledek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f86819db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market: M AA1 R K AH0 T | M AA1 R K IH0 T\n",
      "records: R AH0 K AO1 R D Z | R EH1 K ER0 D Z | R IH0 K AO1 R D Z\n",
      "tomorrow: T AH0 M AA1 R OW2 | T UW0 M AA1 R OW2\n",
      "the: DH AH0 | DH AH1 | DH IY0\n",
      "are: AA1 R | ER0\n"
     ]
    }
   ],
   "source": [
    "for key, val in diff_pron_no_lst.items():\n",
    "    print(key + ': ' + ' | '.join(w for w in val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396110d",
   "metadata": {},
   "source": [
    "## 7. Slabiky\n",
    "\n",
    "Z našeho pozorování u úkolu 4 víme, že čísla u jednotlivých fonémů značí přízvuk. Díky těmto číslům jsme ale kromě přízvuku schopni i odvodit počet slabik. V následující sadě úkolů napíšeme funkci vypisující počet slabik a poté ve slovníku vyhledáme lexikální jednotky, které mají výslovnostní varianty lišící se v počtu slabik.\n",
    "\n",
    "**Úkol 22:**\n",
    "\n",
    "1. Požádejte uživatele o zadání anglické věty. Vstup uložte do proměnné `sent3`,\n",
    "2. normalizujte větu,\n",
    "3. tokenizujte větu,\n",
    "4. vytvořte dictionary s výslovnostními variantami, použijte funkci `pron_dict` nebo `pron_defdict` z řešení, dictionary dále nijak neupravujte.\n",
    "\n",
    "Poznámka: Řešení používá funkci `pron_defdict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce649598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an English sentence: record, antifungal, market, bubble\n"
     ]
    }
   ],
   "source": [
    "sent3 = input('Enter an English sentence: ')\n",
    "sent3 = normalize(sent3)\n",
    "sent3 = tokenize(sent3)\n",
    "sent3 = pron_defdict(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af327e",
   "metadata": {},
   "source": [
    "Všimněte si, že pokud do samostatné buňky zadáte pouze proměnnou, po stisku klávesy Enter se daná proměnná vypíše."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11ca7dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'record': [['R', 'AH0', 'K', 'AO1', 'R', 'D'],\n",
       "              ['R', 'EH1', 'K', 'ER0', 'D'],\n",
       "              ['R', 'IH0', 'K', 'AO1', 'R', 'D']],\n",
       "             'antifungal': [['AE2',\n",
       "               'N',\n",
       "               'T',\n",
       "               'AY2',\n",
       "               'F',\n",
       "               'AH1',\n",
       "               'NG',\n",
       "               'G',\n",
       "               'AH0',\n",
       "               'L'],\n",
       "              ['AE2', 'N', 'T', 'IY2', 'F', 'AH1', 'NG', 'G', 'AH0', 'L']],\n",
       "             'market': [['M', 'AA1', 'R', 'K', 'AH0', 'T'],\n",
       "              ['M', 'AA1', 'R', 'K', 'IH0', 'T']],\n",
       "             'bubble': [['B', 'AH1', 'B', 'AH0', 'L']]})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4dfff3",
   "metadata": {},
   "source": [
    "Nyní máme větu předpřipravenou a můžeme napsat funkci `find_syllab`, která vyhledá počet slabik. Výsledky uloží do nového dictionary, kde klíč bude hledané slovo a hodnota bude list obsahující počet slabik ke každé výslovnostní variantě.\n",
    "\n",
    "**Úkol 23:** \n",
    "\n",
    "1. Vytvořte funkci `find_syllab` s parametrem `sentence_dict`,\n",
    "2. deklarujte nový dictionary `syllab` (použijte buď klasický dictionary nebo defaultdict),\n",
    "3. projděte všechny key-value páry v dictionary `sentence_dict`,\n",
    "4. u každé výslovnostní varianty zjistěte, kolik má slabik,\n",
    "5. výsledek uložte do dictionary `syllab`, kde klíč bude slovo a hodnoty budou počet slabik, např. pro slovo \"record\" by tedy záznam v dictionary vypadal následovně: `'record': [2, 2, 2]`,\n",
    "6. vraťte dictionary `syllab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6406dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_syllab(sentence_dict):\n",
    "    \"\"\" Find a number of syllables in words \"\"\"\n",
    "    syllab = defaultdict(list) #create a new defaultdict object\n",
    "    pattern = re.compile('\\d') #regex pattern for finding digits\n",
    "    \n",
    "    for key, val in sentence_dict.items(): #iterate through key-value pairs in the sentence pronunciation dictionary\n",
    "        for pron in val: #for every pronunciation variant\n",
    "            syllab_count = 0 #set syllables counter to 0\n",
    "            for phon in pron: #for every phoneme in the pronunciation variant\n",
    "                if re.search(pattern, phon): #if the phoneme contains a digit\n",
    "                    syllab_count += 1 #raise the value of the syllables counter by 1\n",
    "            syllab[key].append(syllab_count) #after you went through every phoneme in the pronunciation variant\n",
    "                                             #append the number of syllables to the word\n",
    "    \n",
    "    return syllab #return the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e65c9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'record': [2, 2, 2], 'antifungal': [4, 4], 'market': [2, 2], 'bubble': [2]})\n"
     ]
    }
   ],
   "source": [
    "syllabs = find_syllab(sent3)\n",
    "print(syllabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32117d9",
   "metadata": {},
   "source": [
    "V závislosti na vámi zvolené anglické větě můžete vidět počet slabik pro dané slovo, případně počet slabik pro každou výslovnostní variantu. S největší pravděpodobností tato čísla budou stejná, znamená to tedy, že dané slovo má pokaždé stejný počet slabik. Mohli bychom se ale ptát, zda existují i slova, u kterých se kromě výslovnosti liší i počet slabik u jejich výslovnostních variant. V následující funkci bude naším cílem zjistit, jestli se taková slova ve CMU Dict vyskytují.\n",
    "\n",
    "**Úkol 24:** V další funkci budeme pracovat s proměnnou `entries`, kterou jsme deklarovali na úplném začátku tohoto notebooku. Proměnnou `entries` vypište a připomeňte si její strukturu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fe5895a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', ['AH0']), ('a.', ['EY1']), ('a', ['EY1']), ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81198070",
   "metadata": {},
   "source": [
    "Prohledat cely entries, najit jen ty, kde se lisi hodnoty seznamu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "155cdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(entries):\n",
    "    a = defaultdict(list)\n",
    "    \n",
    "    for entry in entries:\n",
    "        a[entry[0]].append(entry[1])\n",
    "        \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da30757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = test(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7438b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst2 = find_syllab(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65c07061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'a': [1, 1],\n",
       "             'a.': [1],\n",
       "             'a42128': [6],\n",
       "             'aaa': [3],\n",
       "             'aaberg': [2],\n",
       "             'aachen': [2],\n",
       "             'aachener': [3],\n",
       "             'aaker': [2],\n",
       "             'aalseth': [2],\n",
       "             'aamodt': [2],\n",
       "             'aancor': [2],\n",
       "             'aardema': [3],\n",
       "             'aardvark': [2],\n",
       "             'aaron': [2],\n",
       "             \"aaron's\": [2],\n",
       "             'aarons': [2],\n",
       "             'aaronson': [3, 3],\n",
       "             \"aaronson's\": [3, 3],\n",
       "             'aarti': [2],\n",
       "             'aase': [1],\n",
       "             'aasen': [2],\n",
       "             'ab': [1, 2],\n",
       "             'ababa': [3, 3],\n",
       "             'abacha': [3],\n",
       "             'aback': [2],\n",
       "             'abaco': [3],\n",
       "             'abacus': [3],\n",
       "             'abad': [2],\n",
       "             'abadaka': [4],\n",
       "             'abadi': [3],\n",
       "             'abadie': [3],\n",
       "             'abair': [2],\n",
       "             'abalkin': [3],\n",
       "             'abalone': [4],\n",
       "             'abalos': [3],\n",
       "             'abandon': [3],\n",
       "             'abandoned': [3],\n",
       "             'abandoning': [4],\n",
       "             'abandonment': [4],\n",
       "             'abandonments': [4],\n",
       "             'abandons': [3],\n",
       "             'abanto': [3],\n",
       "             'abarca': [3],\n",
       "             'abare': [3],\n",
       "             'abascal': [3],\n",
       "             'abash': [2],\n",
       "             'abashed': [2],\n",
       "             'abate': [2],\n",
       "             'abated': [3],\n",
       "             'abatement': [3],\n",
       "             'abatements': [3],\n",
       "             'abates': [2],\n",
       "             'abating': [3],\n",
       "             'abba': [2],\n",
       "             'abbado': [3],\n",
       "             'abbas': [2],\n",
       "             'abbasi': [3],\n",
       "             'abbate': [2],\n",
       "             'abbatiello': [5],\n",
       "             'abbe': [2, 2],\n",
       "             'abbenhaus': [3],\n",
       "             'abbett': [2],\n",
       "             'abbeville': [2],\n",
       "             'abbey': [2],\n",
       "             \"abbey's\": [2],\n",
       "             'abbie': [2],\n",
       "             'abbitt': [2],\n",
       "             'abbot': [2],\n",
       "             'abbotstown': [3],\n",
       "             'abbott': [2],\n",
       "             \"abbott's\": [2],\n",
       "             'abbottstown': [3],\n",
       "             'abboud': [2, 2],\n",
       "             'abbreviate': [4],\n",
       "             'abbreviated': [5, 5],\n",
       "             'abbreviates': [4],\n",
       "             'abbreviating': [5],\n",
       "             'abbreviation': [5],\n",
       "             'abbreviations': [5],\n",
       "             'abbruzzese': [4],\n",
       "             'abbs': [1],\n",
       "             'abby': [2],\n",
       "             'abco': [2],\n",
       "             'abcotek': [3],\n",
       "             'abdalla': [3],\n",
       "             'abdallah': [3],\n",
       "             'abdel': [2],\n",
       "             'abdella': [3],\n",
       "             'abdicate': [3],\n",
       "             'abdicated': [4],\n",
       "             'abdicates': [3],\n",
       "             'abdicating': [4],\n",
       "             'abdication': [4],\n",
       "             'abdnor': [2],\n",
       "             'abdo': [2],\n",
       "             'abdollah': [3],\n",
       "             'abdomen': [3, 3],\n",
       "             'abdominal': [4, 4],\n",
       "             'abduct': [2],\n",
       "             'abducted': [3, 3],\n",
       "             'abductee': [3],\n",
       "             'abductees': [3],\n",
       "             'abducting': [3, 3],\n",
       "             'abduction': [3, 3],\n",
       "             'abductions': [3, 3],\n",
       "             'abductor': [3, 3],\n",
       "             'abductors': [3, 3],\n",
       "             'abducts': [2],\n",
       "             'abdul': [2],\n",
       "             'abdulaziz': [4],\n",
       "             'abdulla': [3],\n",
       "             'abdullah': [3],\n",
       "             'abe': [1],\n",
       "             'abed': [2],\n",
       "             'abedi': [3],\n",
       "             'abee': [2],\n",
       "             'abel': [2],\n",
       "             'abela': [3],\n",
       "             'abelard': [3],\n",
       "             'abele': [2],\n",
       "             'abeles': [2, 3],\n",
       "             'abell': [2],\n",
       "             'abella': [3],\n",
       "             'abeln': [2],\n",
       "             'abelow': [3],\n",
       "             'abels': [2],\n",
       "             'abelson': [3],\n",
       "             'abend': [2, 2],\n",
       "             'abendroth': [3],\n",
       "             'aber': [2],\n",
       "             'abercrombie': [4],\n",
       "             'aberdeen': [3],\n",
       "             'aberford': [3],\n",
       "             'aberg': [2],\n",
       "             'aberle': [3, 2],\n",
       "             'abermin': [3],\n",
       "             'abernathy': [4],\n",
       "             'abernethy': [4],\n",
       "             'aberrant': [3],\n",
       "             'aberration': [4],\n",
       "             'aberrational': [5],\n",
       "             'aberrations': [4],\n",
       "             'abert': [2],\n",
       "             'abet': [2],\n",
       "             'abetted': [3],\n",
       "             'abetting': [3],\n",
       "             'abex': [2],\n",
       "             'abeyance': [3],\n",
       "             'abeyta': [3],\n",
       "             'abhor': [2],\n",
       "             'abhorred': [2],\n",
       "             'abhorrence': [3],\n",
       "             'abhorrent': [3],\n",
       "             'abhors': [2],\n",
       "             'abiam': [3],\n",
       "             \"abiam's\": [3],\n",
       "             'abid': [2],\n",
       "             'abide': [2],\n",
       "             'abided': [3],\n",
       "             'abides': [2],\n",
       "             'abiding': [3],\n",
       "             'abidjan': [3],\n",
       "             'abie': [2],\n",
       "             'abigail': [3],\n",
       "             'abila': [3],\n",
       "             'abilene': [3],\n",
       "             'abilities': [4],\n",
       "             'ability': [4],\n",
       "             'abimael': [3],\n",
       "             'abimaels': [3],\n",
       "             'abingdon': [3],\n",
       "             'abington': [3],\n",
       "             'abio': [3],\n",
       "             'abiola': [4],\n",
       "             \"abiola's\": [4],\n",
       "             'abiomed': [4],\n",
       "             'abiquiu': [3],\n",
       "             'abitibi': [4],\n",
       "             'abitz': [2],\n",
       "             'abject': [2],\n",
       "             'abkhazia': [3, 3],\n",
       "             'abkhazian': [4, 4, 3, 3],\n",
       "             'abkhazians': [4, 4],\n",
       "             'ablaze': [2],\n",
       "             'able': [2],\n",
       "             'able-bodied': [4],\n",
       "             'abled': [2],\n",
       "             'abler': [3, 2],\n",
       "             'ables': [2],\n",
       "             'ablest': [2, 2],\n",
       "             'abloom': [2],\n",
       "             'ably': [2],\n",
       "             'abner': [2],\n",
       "             'abney': [2],\n",
       "             'abnormal': [3],\n",
       "             'abnormalities': [5],\n",
       "             'abnormality': [5],\n",
       "             'abnormally': [4],\n",
       "             'abo': [2],\n",
       "             'aboard': [2],\n",
       "             'abode': [2],\n",
       "             'abohalima': [5],\n",
       "             'abolish': [3],\n",
       "             'abolished': [3],\n",
       "             'abolishes': [4],\n",
       "             'abolishing': [4],\n",
       "             'abolition': [4],\n",
       "             'abolitionism': [6],\n",
       "             'abolitionist': [5],\n",
       "             'abolitionists': [5, 5],\n",
       "             'abominable': [5],\n",
       "             'abomination': [5],\n",
       "             'abood': [2],\n",
       "             'aboodi': [3],\n",
       "             'abor': [2],\n",
       "             'aboriginal': [5],\n",
       "             'aborigine': [5],\n",
       "             'aborigines': [5],\n",
       "             'aborn': [2],\n",
       "             'abort': [2],\n",
       "             'aborted': [3],\n",
       "             'abortifacient': [5],\n",
       "             'abortifacients': [5],\n",
       "             'aborting': [3],\n",
       "             'abortion': [3],\n",
       "             'abortionist': [4],\n",
       "             'abortionists': [4, 4],\n",
       "             'abortions': [3],\n",
       "             'abortive': [3],\n",
       "             'aborts': [2],\n",
       "             \"abo's\": [2],\n",
       "             'abott': [2],\n",
       "             'abou': [2],\n",
       "             'aboud': [2],\n",
       "             'abouhalima': [5],\n",
       "             \"abouhalima's\": [5],\n",
       "             'abound': [2],\n",
       "             'abounded': [3],\n",
       "             'abounding': [3],\n",
       "             'abounds': [2],\n",
       "             'about': [2],\n",
       "             \"about's\": [2],\n",
       "             'above': [2],\n",
       "             'aboveboard': [3],\n",
       "             \"above's\": [2],\n",
       "             'abplanalp': [3],\n",
       "             'abra': [2],\n",
       "             'abracadabra': [5],\n",
       "             'abraham': [3],\n",
       "             'abrahamian': [5],\n",
       "             'abrahams': [3],\n",
       "             'abrahamsen': [4],\n",
       "             'abrahamson': [4],\n",
       "             'abram': [2],\n",
       "             'abramczyk': [3],\n",
       "             'abramo': [3],\n",
       "             'abramovitz': [4],\n",
       "             'abramowicz': [4],\n",
       "             'abramowitz': [4],\n",
       "             \"abram's\": [2],\n",
       "             'abrams': [2],\n",
       "             'abramson': [3],\n",
       "             \"abrams's\": [3],\n",
       "             'abrasion': [3],\n",
       "             'abrasions': [3],\n",
       "             'abrasive': [3],\n",
       "             'abrasives': [3],\n",
       "             'abraxa': [3],\n",
       "             \"abraxa's\": [3],\n",
       "             'abraxas': [3],\n",
       "             'abreast': [2],\n",
       "             'abrego': [3],\n",
       "             'abreu': [2],\n",
       "             'abridge': [2],\n",
       "             'abridged': [2],\n",
       "             'abridgement': [3],\n",
       "             'abridges': [3],\n",
       "             'abridging': [3],\n",
       "             'abril': [2],\n",
       "             'abroad': [2],\n",
       "             'abrogate': [3],\n",
       "             'abrogated': [4],\n",
       "             'abrogating': [4],\n",
       "             'abrogation': [4],\n",
       "             'abrol': [2],\n",
       "             'abron': [2],\n",
       "             'abrupt': [2],\n",
       "             'abruptly': [3],\n",
       "             'abruptness': [3],\n",
       "             'abrutyn': [3],\n",
       "             'abruzzese': [4],\n",
       "             'abruzzo': [3],\n",
       "             'abs': [3, 1],\n",
       "             'absalom': [3],\n",
       "             'absaraka': [4],\n",
       "             'abscam': [2],\n",
       "             'abscess': [2],\n",
       "             'abscond': [2],\n",
       "             'absconded': [3],\n",
       "             'absconding': [3],\n",
       "             'absconds': [2],\n",
       "             'absecon': [3],\n",
       "             'absence': [2],\n",
       "             'absences': [3],\n",
       "             'absent': [2],\n",
       "             'absentee': [3],\n",
       "             'absenteeism': [5],\n",
       "             'absentees': [3],\n",
       "             'absentia': [3],\n",
       "             'absher': [2],\n",
       "             'abshier': [3],\n",
       "             'abshire': [2],\n",
       "             'absinthe': [2],\n",
       "             'abso': [2],\n",
       "             'absolom': [3],\n",
       "             'absolut': [3],\n",
       "             'absolute': [3],\n",
       "             'absolutely': [4],\n",
       "             'absoluteness': [4],\n",
       "             'absolutes': [3],\n",
       "             'absolution': [4],\n",
       "             'absolutism': [5],\n",
       "             'absolutist': [4],\n",
       "             \"absolut's\": [3],\n",
       "             'absolve': [2, 2],\n",
       "             'absolved': [2, 2],\n",
       "             'absolves': [2, 2],\n",
       "             'absolving': [3, 3],\n",
       "             'absorb': [2],\n",
       "             'absorbed': [2],\n",
       "             'absorbency': [4],\n",
       "             'absorbent': [3],\n",
       "             'absorber': [3],\n",
       "             'absorbers': [3],\n",
       "             'absorbing': [3],\n",
       "             'absorbs': [2],\n",
       "             'absorption': [3, 3],\n",
       "             'abstain': [2, 2],\n",
       "             'abstained': [2, 2],\n",
       "             'abstaining': [3, 3],\n",
       "             'abstention': [3, 3],\n",
       "             'abstentions': [3, 3],\n",
       "             'abstinence': [3],\n",
       "             'abstinent': [3],\n",
       "             'abston': [2],\n",
       "             'abstract': [2, 2],\n",
       "             'abstracted': [3],\n",
       "             'abstraction': [3],\n",
       "             'abstractions': [3],\n",
       "             'abstracts': [2],\n",
       "             'abstruse': [2],\n",
       "             'absurd': [2],\n",
       "             'absurdist': [3],\n",
       "             'absurdities': [4],\n",
       "             'absurdity': [4],\n",
       "             'absurdly': [3],\n",
       "             'abt': [1, 3],\n",
       "             'abts': [1, 3, 4],\n",
       "             'abu': [2],\n",
       "             'abudrahm': [3],\n",
       "             'abuellah': [3],\n",
       "             \"abuellah's\": [3],\n",
       "             'abuladze': [4],\n",
       "             'abundance': [3],\n",
       "             'abundant': [3],\n",
       "             'abundantly': [4],\n",
       "             'aburto': [3],\n",
       "             \"aburto's\": [3],\n",
       "             'abuse': [2, 2],\n",
       "             'abused': [2],\n",
       "             'abuser': [3],\n",
       "             'abusers': [3],\n",
       "             'abuses': [3, 3],\n",
       "             'abusing': [3],\n",
       "             'abusive': [3],\n",
       "             'abut': [2],\n",
       "             'abuts': [2],\n",
       "             'abutted': [3],\n",
       "             'abutting': [3],\n",
       "             'abuzz': [2],\n",
       "             'abysmal': [3],\n",
       "             'abysmally': [4],\n",
       "             'abyss': [2],\n",
       "             'abyssinia': [4],\n",
       "             'abyssinian': [4],\n",
       "             'abzug': [2, 2],\n",
       "             'ac': [2],\n",
       "             'aca': [2],\n",
       "             'acacia': [3],\n",
       "             'academe': [3],\n",
       "             'academia': [5],\n",
       "             'academic': [4],\n",
       "             'academically': [5],\n",
       "             'academician': [5],\n",
       "             'academicians': [5, 5],\n",
       "             'academics': [4],\n",
       "             'academies': [4],\n",
       "             'academy': [4],\n",
       "             \"academy's\": [4],\n",
       "             'acadia': [4],\n",
       "             'acampo': [3],\n",
       "             'acampora': [4],\n",
       "             'acantha': [3],\n",
       "             'acapulco': [4],\n",
       "             'acary': [3],\n",
       "             'accardi': [3],\n",
       "             'accardo': [3],\n",
       "             'accede': [2],\n",
       "             'acceded': [3],\n",
       "             'accedes': [2],\n",
       "             'acceding': [3],\n",
       "             'accel': [2],\n",
       "             'accelerant': [4],\n",
       "             'accelerants': [4],\n",
       "             'accelerate': [4],\n",
       "             'accelerated': [5],\n",
       "             'accelerates': [4],\n",
       "             'accelerating': [5],\n",
       "             'acceleration': [5],\n",
       "             'accelerator': [5],\n",
       "             'accelerators': [5],\n",
       "             'accelerometer': [6],\n",
       "             'accelerometers': [6],\n",
       "             'accent': [2, 2],\n",
       "             'accented': [3],\n",
       "             'accenting': [3],\n",
       "             'accents': [2],\n",
       "             'accentuate': [4],\n",
       "             'accentuated': [5],\n",
       "             'accentuates': [4],\n",
       "             'accentuating': [5],\n",
       "             'accept': [2, 2],\n",
       "             'acceptability': [6],\n",
       "             'acceptable': [4, 4],\n",
       "             'acceptably': [4, 4],\n",
       "             'acceptance': [3, 3],\n",
       "             'acceptances': [4],\n",
       "             'accepted': [3, 3],\n",
       "             'accepting': [3, 3],\n",
       "             'accepts': [2],\n",
       "             'access': [2],\n",
       "             'accessed': [2],\n",
       "             'accessibility': [6],\n",
       "             'accessible': [4],\n",
       "             'accessing': [3],\n",
       "             'accession': [3],\n",
       "             'accessories': [4],\n",
       "             'accessorize': [4],\n",
       "             'accessorized': [4],\n",
       "             'accessory': [4],\n",
       "             'accetta': [3],\n",
       "             'accident': [3],\n",
       "             'accidental': [4, 4],\n",
       "             'accidentally': [5, 5],\n",
       "             'accidently': [4],\n",
       "             \"accident's\": [3],\n",
       "             'accidents': [3],\n",
       "             'accion': [3],\n",
       "             'accival': [3],\n",
       "             'acclaim': [2],\n",
       "             'acclaimed': [2],\n",
       "             'acclaiming': [3],\n",
       "             \"acclaim's\": [2],\n",
       "             'acclaims': [2],\n",
       "             'acclamation': [4],\n",
       "             'acclimate': [3],\n",
       "             'acclimated': [4],\n",
       "             'acclimation': [4],\n",
       "             'acco': [2],\n",
       "             'accokeek': [3],\n",
       "             'accola': [3],\n",
       "             'accolade': [3],\n",
       "             'accolades': [3],\n",
       "             'accomando': [4],\n",
       "             'accommodate': [4],\n",
       "             'accommodated': [5],\n",
       "             'accommodates': [4],\n",
       "             'accommodating': [5],\n",
       "             'accommodation': [5],\n",
       "             'accommodations': [5],\n",
       "             'accommodative': [5],\n",
       "             'accompanied': [4],\n",
       "             'accompanies': [4],\n",
       "             'accompaniment': [4, 4],\n",
       "             'accompaniments': [4, 4],\n",
       "             'accompanist': [4],\n",
       "             'accompany': [4],\n",
       "             'accompanying': [5],\n",
       "             'accompli': [3, 3],\n",
       "             'accomplice': [3],\n",
       "             'accomplices': [4],\n",
       "             'accomplish': [3],\n",
       "             'accomplished': [3],\n",
       "             'accomplishes': [4],\n",
       "             'accomplishing': [4],\n",
       "             'accomplishment': [4],\n",
       "             'accomplishments': [4],\n",
       "             'accor': [2],\n",
       "             'accord': [2],\n",
       "             'accordance': [3],\n",
       "             'accorded': [3],\n",
       "             'according': [3],\n",
       "             'accordingly': [4],\n",
       "             'accordion': [4],\n",
       "             'accordions': [4],\n",
       "             \"accord's\": [2],\n",
       "             'accords': [2],\n",
       "             \"accor's\": [2],\n",
       "             'accost': [2],\n",
       "             'accosted': [3],\n",
       "             'accosting': [3],\n",
       "             'account': [2],\n",
       "             'accountability': [6, 6],\n",
       "             'accountable': [4, 4],\n",
       "             'accountancy': [4],\n",
       "             'accountant': [3],\n",
       "             \"accountant's\": [3],\n",
       "             'accountants': [3],\n",
       "             \"accountants'\": [3],\n",
       "             'accounted': [3, 3],\n",
       "             'accountemp': [3],\n",
       "             'accountemps': [3],\n",
       "             'accounting': [3, 3],\n",
       "             \"account's\": [2],\n",
       "             'accounts': [2],\n",
       "             'accouterment': [4],\n",
       "             'accouterments': [4],\n",
       "             'accoutrement': [4],\n",
       "             'accoutrements': [4],\n",
       "             'accredit': [3],\n",
       "             'accreditation': [5],\n",
       "             'accreditations': [5],\n",
       "             'accredited': [4],\n",
       "             'accrediting': [4],\n",
       "             'accreted': [3],\n",
       "             'accretion': [3],\n",
       "             'accrual': [3],\n",
       "             'accruals': [3],\n",
       "             'accrue': [2],\n",
       "             'accrued': [2],\n",
       "             'accrues': [2],\n",
       "             'accruing': [3],\n",
       "             'accu': [2],\n",
       "             'accuhealth': [3],\n",
       "             'accumulate': [4],\n",
       "             'accumulated': [5],\n",
       "             'accumulates': [4],\n",
       "             'accumulating': [5],\n",
       "             'accumulation': [5],\n",
       "             'accumulations': [5],\n",
       "             'accumulative': [5],\n",
       "             'accumulatively': [6, 6],\n",
       "             'accumulator': [5],\n",
       "             'accumulators': [5],\n",
       "             'accuracies': [4],\n",
       "             'accuracy': [4],\n",
       "             'accurate': [3],\n",
       "             'accurately': [4],\n",
       "             'accuray': [3],\n",
       "             \"accuray's\": [3],\n",
       "             'accuride': [3],\n",
       "             'accurso': [3],\n",
       "             'accusation': [4, 4],\n",
       "             'accusations': [4, 4],\n",
       "             'accusative': [4],\n",
       "             'accusatory': [5],\n",
       "             'accuse': [2],\n",
       "             'accused': [2],\n",
       "             'accuser': [3],\n",
       "             'accusers': [3],\n",
       "             'accuses': [3],\n",
       "             'accusing': [3],\n",
       "             'accusingly': [4],\n",
       "             'accustom': [3],\n",
       "             'accustomed': [3],\n",
       "             'accutane': [3],\n",
       "             'ace': [1],\n",
       "             'acecomm': [2],\n",
       "             'aced': [1],\n",
       "             'acer': [2],\n",
       "             'acerbic': [3],\n",
       "             'acero': [3, 3, 3],\n",
       "             'acerra': [3],\n",
       "             'aces': [2],\n",
       "             'acetaminophen': [6],\n",
       "             'acetate': [3],\n",
       "             'acetic': [3, 3],\n",
       "             'aceto': [3],\n",
       "             'acetochlor': [4],\n",
       "             'acetone': [3],\n",
       "             'acetosyringone': [6],\n",
       "             'acetylcholine': [5, 5],\n",
       "             'acetylene': [4],\n",
       "             'acevedo': [4],\n",
       "             'aceves': [3],\n",
       "             'acey': [2],\n",
       "             'achaean': [3],\n",
       "             'achatz': [2],\n",
       "             'ache': [1],\n",
       "             'achebe': [3],\n",
       "             'ached': [1],\n",
       "             'achee': [2],\n",
       "             'achenbach': [3],\n",
       "             'achenbaum': [3],\n",
       "             'aches': [1],\n",
       "             'acheson': [3],\n",
       "             \"acheson's\": [3],\n",
       "             'achesons': [3],\n",
       "             'achey': [2],\n",
       "             'achieva': [3],\n",
       "             'achievable': [4],\n",
       "             'achieve': [2],\n",
       "             'achieved': [2],\n",
       "             'achievement': [3],\n",
       "             'achievements': [3],\n",
       "             'achiever': [3],\n",
       "             'achievers': [3],\n",
       "             'achieves': [2],\n",
       "             'achieving': [3],\n",
       "             'achille': [3],\n",
       "             'achilles': [3],\n",
       "             \"achilles'\": [3],\n",
       "             'aching': [2],\n",
       "             'achingly': [3],\n",
       "             'achmed': [2],\n",
       "             'achoa': [3],\n",
       "             \"achoa's\": [3],\n",
       "             'achor': [2],\n",
       "             'achord': [2],\n",
       "             'achorn': [2],\n",
       "             'achtenberg': [3],\n",
       "             'achterberg': [3],\n",
       "             'achy': [2],\n",
       "             'acid': [2],\n",
       "             'acidic': [3],\n",
       "             'acidification': [6],\n",
       "             'acidified': [4],\n",
       "             'acidifies': [4],\n",
       "             'acidify': [4],\n",
       "             'acidity': [4],\n",
       "             'acidly': [3],\n",
       "             'acidosis': [4],\n",
       "             'acids': [2],\n",
       "             'aciduria': [5],\n",
       "             'acierno': [3],\n",
       "             'ack': [1],\n",
       "             'acker': [2],\n",
       "             'ackerley': [3],\n",
       "             'ackerly': [3],\n",
       "             'ackerman': [3],\n",
       "             'ackermann': [3],\n",
       "             'ackermanville': [4],\n",
       "             \"acker's\": [2],\n",
       "             'ackerson': [3],\n",
       "             'ackert': [2],\n",
       "             'ackhouse': [2],\n",
       "             'ackland': [2],\n",
       "             'ackles': [2],\n",
       "             'ackley': [2],\n",
       "             'acklin': [2],\n",
       "             'ackman': [2],\n",
       "             'acknowledge': [3, 3],\n",
       "             'acknowledgeable': [5, 5],\n",
       "             'acknowledged': [3, 3],\n",
       "             'acknowledgement': [4, 4],\n",
       "             'acknowledgements': [4, 4],\n",
       "             'acknowledges': [4, 4],\n",
       "             'acknowledging': [4, 4],\n",
       "             'acknowledgment': [4, 4],\n",
       "             'ackroyd': [2],\n",
       "             \"ackroyd's\": [2],\n",
       "             'acmat': [2],\n",
       "             \"acmat's\": [2],\n",
       "             'acme': [2],\n",
       "             \"acme's\": [2],\n",
       "             'acne': [2],\n",
       "             'acocella': [4],\n",
       "             'acoff': [2],\n",
       "             'acog': [2],\n",
       "             'acolyte': [3],\n",
       "             'acolytes': [3],\n",
       "             'acord': [2],\n",
       "             'acordia': [4],\n",
       "             'acorn': [2],\n",
       "             \"acorn's\": [2],\n",
       "             'acorns': [2],\n",
       "             'acosta': [3],\n",
       "             'acott': [2],\n",
       "             'acoustic': [3],\n",
       "             'acoustical': [4],\n",
       "             'acoustically': [4],\n",
       "             'acoustics': [3],\n",
       "             'acquaint': [2],\n",
       "             'acquaintance': [3],\n",
       "             'acquaintances': [4],\n",
       "             'acquaintanceship': [4],\n",
       "             'acquainted': [3, 3],\n",
       "             'acquaviva': [4],\n",
       "             'acquiesce': [3],\n",
       "             'acquiesced': [3],\n",
       "             'acquiescence': [4],\n",
       "             'acquiescing': [4],\n",
       "             'acquire': [3],\n",
       "             'acquired': [3],\n",
       "             'acquirer': [4],\n",
       "             \"acquirer's\": [4],\n",
       "             'acquirers': [4],\n",
       "             'acquires': [3],\n",
       "             'acquiring': [3, 4],\n",
       "             'acquisition': [4],\n",
       "             \"acquisition's\": [4],\n",
       "             'acquisitions': [4],\n",
       "             'acquisitive': [4],\n",
       "             'acquit': [2],\n",
       "             'acquitaine': [3],\n",
       "             'acquits': [2],\n",
       "             'acquittal': [3],\n",
       "             'acquittals': [3],\n",
       "             'acquitted': [3, 3],\n",
       "             'acquitting': [3],\n",
       "             'acre': [2],\n",
       "             'acreage': [3, 2],\n",
       "             'acree': [2],\n",
       "             'acres': [2],\n",
       "             'acrey': [2],\n",
       "             'acri': [2],\n",
       "             'acrid': [2],\n",
       "             'acrimonious': [5],\n",
       "             'acrimony': [4],\n",
       "             'acro': [2],\n",
       "             'acrobat': [3],\n",
       "             'acrobatic': [4],\n",
       "             'acrobatics': [4],\n",
       "             'acrobats': [3],\n",
       "             'acrolein': [3],\n",
       "             'acronym': [3],\n",
       "             'acronyms': [3],\n",
       "             'acropolis': [4],\n",
       "             'across': [2],\n",
       "             'acrylic': [3],\n",
       "             'acrylics': [3],\n",
       "             'act': [1],\n",
       "             'actava': [3],\n",
       "             \"actava's\": [3],\n",
       "             'actavas': [3],\n",
       "             'acted': [2, 2],\n",
       "             'actel': [2],\n",
       "             'actigall': [3],\n",
       "             'actin': [2],\n",
       "             'acting': [2],\n",
       "             'actinide': [3],\n",
       "             'actinidia': [5],\n",
       "             'actinomycosis': [6],\n",
       "             'action': [2],\n",
       "             'actionable': [4],\n",
       "             \"action's\": [2],\n",
       "             'actions': [2],\n",
       "             'activase': [3],\n",
       "             'activate': [3],\n",
       "             'activated': [4, 4],\n",
       "             'activates': [3],\n",
       "             'activating': [4],\n",
       "             'activation': [4],\n",
       "             'activator': [4],\n",
       "             'active': [2],\n",
       "             'actively': [3],\n",
       "             \"active's\": [2],\n",
       "             'actives': [2],\n",
       "             'activision': [4],\n",
       "             'activism': [4],\n",
       "             'activist': [3, 3],\n",
       "             'activists': [3, 3, 3, 3],\n",
       "             \"activists'\": [3, 3],\n",
       "             'activities': [4, 4],\n",
       "             'activity': [4, 4],\n",
       "             'actmedia': [4],\n",
       "             'actodine': [3],\n",
       "             'acton': [2],\n",
       "             'actor': [2],\n",
       "             \"actor's\": [2],\n",
       "             'actors': [2],\n",
       "             \"actors'\": [2],\n",
       "             'actress': [2],\n",
       "             'actresses': [3],\n",
       "             \"actress's\": [3],\n",
       "             \"act's\": [1],\n",
       "             'acts': [1, 1],\n",
       "             'actual': [3, 2],\n",
       "             'actuality': [5],\n",
       "             'actualize': [4],\n",
       "             'actually': [4, 2, 2, 3],\n",
       "             'actuarial': [5],\n",
       "             'actuaries': [4],\n",
       "             'actuary': [4],\n",
       "             'actuate': [3],\n",
       "             'actuator': [4, 4],\n",
       "             'actuators': [4, 4],\n",
       "             'actus': [2],\n",
       "             'acuff': [2],\n",
       "             'acuity': [4],\n",
       "             'acumen': [3],\n",
       "             'acuna': [3],\n",
       "             'acupuncture': [4],\n",
       "             'acura': [3],\n",
       "             \"acura's\": [3],\n",
       "             'acuras': [3],\n",
       "             'acuson': [3],\n",
       "             'acustar': [3],\n",
       "             'acusyst': [3],\n",
       "             'acute': [2],\n",
       "             'acutely': [3],\n",
       "             'acuteness': [3],\n",
       "             'acyclovir': [4],\n",
       "             'ad': [1],\n",
       "             'ada': [2],\n",
       "             'adabel': [3],\n",
       "             'adabelle': [3],\n",
       "             'adachi': [3],\n",
       "             'adage': [2, 2],\n",
       "             'adagio': [4],\n",
       "             'adah': [2],\n",
       "             'adair': [2],\n",
       "             'adaire': [2],\n",
       "             'adak': [2],\n",
       "             'adalah': [3],\n",
       "             'adalia': [4],\n",
       "             'adam': [2],\n",
       "             'adamant': [3],\n",
       "             'adamantly': [4],\n",
       "             'adamcik': [3],\n",
       "             'adamczak': [3],\n",
       "             'adamczyk': [3],\n",
       "             'adame': [3],\n",
       "             'adamec': [3],\n",
       "             'adamek': [3],\n",
       "             'adames': [2],\n",
       "             'adami': [3],\n",
       "             'adamik': [3],\n",
       "             'adamina': [4],\n",
       "             'adamkus': [3],\n",
       "             'adamo': [3],\n",
       "             'adamowicz': [4],\n",
       "             \"adam's\": [2],\n",
       "             'adams': [2],\n",
       "             \"adams'\": [2],\n",
       "             'adamski': [3],\n",
       "             'adamson': [3],\n",
       "             \"adams's\": [3],\n",
       "             'adamstown': [3],\n",
       "             'adan': [2],\n",
       "             'adapso': [3],\n",
       "             'adapt': [2],\n",
       "             'adaptability': [6],\n",
       "             'adaptable': [4],\n",
       "             'adaptaplex': [4],\n",
       "             'adaptation': [4],\n",
       "             'adaptations': [4, 4],\n",
       "             'adaptec': [3],\n",
       "             \"adaptec's\": [3],\n",
       "             'adapted': [3, 3],\n",
       "             'adapter': [3],\n",
       "             'adapters': [3],\n",
       "             'adapting': [3],\n",
       "             'adaptive': [3],\n",
       "             'adaptor': [3],\n",
       "             'adaptors': [3],\n",
       "             'adapts': [2],\n",
       "             'adar': [2],\n",
       "             'adarand': [3],\n",
       "             \"ada's\": [2],\n",
       "             'adas': [2],\n",
       "             'aday': [2],\n",
       "             'adaza': [3],\n",
       "             'adcock': [2],\n",
       "             'adcox': [2],\n",
       "             'add': [1],\n",
       "             'addair': [2],\n",
       "             'addams': [2],\n",
       "             'added': [2, 2],\n",
       "             'addendum': [3],\n",
       "             'addendums': [3],\n",
       "             'addeo': [3],\n",
       "             'adder': [2],\n",
       "             'adderley': [3],\n",
       "             'addicks': [2],\n",
       "             'addict': [2, 2],\n",
       "             'addicted': [3, 3],\n",
       "             'addicting': [3],\n",
       "             'addiction': [3],\n",
       "             'addictions': [3],\n",
       "             'addictive': [3],\n",
       "             'addicts': [2, 2],\n",
       "             'addidas': [3],\n",
       "             \"addidas'\": [3],\n",
       "             'addidases': [4],\n",
       "             \"addidas's\": [4],\n",
       "             'addie': [2],\n",
       "             'adding': [2],\n",
       "             'addington': [3],\n",
       "             'addis': [2],\n",
       "             'addis-ababa': [5, 5],\n",
       "             'addison': [3, 3],\n",
       "             \"addison's\": [3],\n",
       "             'addition': [3],\n",
       "             'additional': [4, 3],\n",
       "             'additionally': [5, 4],\n",
       "             'additions': [3],\n",
       "             'additive': [3, 3],\n",
       "             'additives': [3, 3],\n",
       "             'addle': [2],\n",
       "             'addled': [2],\n",
       "             'addleman': [3],\n",
       "             'address': [2, 2],\n",
       "             'addressable': [4],\n",
       "             'addressed': [2],\n",
       "             'addressee': [3],\n",
       "             'addresses': [3, 3],\n",
       "             'addressing': [3],\n",
       "             'adds': [1],\n",
       "             'adduci': [3],\n",
       "             'adduct': [2],\n",
       "             'addwest': [2],\n",
       "             'addy': [2],\n",
       "             'addyston': [3],\n",
       "             'ade': [1],\n",
       "             'adee': [2],\n",
       "             'adel': [2],\n",
       "             'adela': [3],\n",
       "             'adelaar': [3],\n",
       "             'adelaide': [3],\n",
       "             'adelanto': [4],\n",
       "             'adelbert': [3],\n",
       "             'adele': [2],\n",
       "             \"adele's\": [2],\n",
       "             'adeline': [3],\n",
       "             'adelizzi': [4],\n",
       "             'adell': [2],\n",
       "             'adelle': [2],\n",
       "             \"adell's\": [2],\n",
       "             'adelman': [3, 3],\n",
       "             'adelmann': [3],\n",
       "             'adelpha': [3],\n",
       "             'adelphi': [3],\n",
       "             'adelphia': [4],\n",
       "             \"adelphia's\": [4],\n",
       "             'adelsberger': [4],\n",
       "             'adelson': [3],\n",
       "             'adelstein': [3, 3],\n",
       "             'aden': [2],\n",
       "             'adena': [3],\n",
       "             'adenauer': [3, 3],\n",
       "             'adenine': [3],\n",
       "             'adenoid': [3],\n",
       "             'adenoids': [3],\n",
       "             'adenoscan': [4],\n",
       "             'adenosine': [4],\n",
       "             'adenovirus': [5],\n",
       "             'adept': [2],\n",
       "             'adequacy': [4],\n",
       "             'adequate': [3, 3],\n",
       "             'adequately': [4, 4],\n",
       "             'ader': [2],\n",
       "             'aderhold': [3],\n",
       "             'aderholt': [3],\n",
       "             'aderman': [3],\n",
       "             'ades': [1],\n",
       "             'adey': [2],\n",
       "             'adger': [2],\n",
       "             'adham': [2],\n",
       "             'adhere': [2],\n",
       "             'adhered': [2],\n",
       "             'adherence': [3],\n",
       "             'adherent': [3],\n",
       "             'adherents': [3],\n",
       "             'adheres': [2],\n",
       "             'adhering': [3],\n",
       "             'adhesion': [3],\n",
       "             'adhesive': [3, 3],\n",
       "             'adhesives': [3, 3],\n",
       "             'ad-hoc': [2],\n",
       "             'adia': [3],\n",
       "             'adid': [2],\n",
       "             'adidas': [3],\n",
       "             \"adidas's\": [4],\n",
       "             'adieu': [2],\n",
       "             'adin': [2],\n",
       "             'adina': [3],\n",
       "             'adine': [3],\n",
       "             'adinolfi': [4],\n",
       "             'adios': [3],\n",
       "             'adipose': [3],\n",
       "             'adirondack': [4],\n",
       "             'adisq': [2, 2],\n",
       "             'adjacent': [3],\n",
       "             'adjani': [3],\n",
       "             'adjective': [3],\n",
       "             'adjectives': [3],\n",
       "             'adjoin': [2],\n",
       "             'adjoining': [3],\n",
       "             'adjoins': [2],\n",
       "             ...})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8482f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
